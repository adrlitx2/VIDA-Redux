import { useRef, useState, useEffect } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import { FaceMesh } from '@mediapipe/face_mesh';
import { Hands } from '@mediapipe/hands';
import { Pose } from '@mediapipe/pose';
import { Camera } from '@mediapipe/camera_utils';

interface TrackingData {
  face: {
    landmarks: number;
    expressions: Record<string, number>;
    headRotation: { x: number; y: number; z: number };
  };
  hands: {
    left: { detected: boolean; landmarks: number; gesture: string };
    right: { detected: boolean; landmarks: number; gesture: string };
  };
  body: {
    pose: { detected: boolean; landmarks: number; confidence: number };
    skeleton: { joints: number; tracking: boolean };
  };
  eyes: {
    left: { openness: number; gaze: { x: number; y: number } };
    right: { openness: number; gaze: { x: number; y: number } };
    blinking: boolean;
  };
  mouth: {
    openness: number;
    shape: string;
    speaking: boolean;
    lipSync: number;
  };
}

export default function ComprehensiveTracking() {
  const [cameraActive, setCameraActive] = useState(false);
  const [trackingData, setTrackingData] = useState<TrackingData>({
    face: { landmarks: 0, expressions: {}, headRotation: { x: 0, y: 0, z: 0 } },
    hands: { 
      left: { detected: false, landmarks: 0, gesture: 'none' },
      right: { detected: false, landmarks: 0, gesture: 'none' }
    },
    body: { pose: { detected: false, landmarks: 0, confidence: 0 }, skeleton: { joints: 0, tracking: false } },
    eyes: { 
      left: { openness: 1, gaze: { x: 0, y: 0 } },
      right: { openness: 1, gaze: { x: 0, y: 0 } },
      blinking: false
    },
    mouth: { openness: 0, shape: 'neutral', speaking: false, lipSync: 0 }
  });
  const [frameCount, setFrameCount] = useState(0);
  const [isCalibrating, setIsCalibrating] = useState(false);
  const [logs, setLogs] = useState<string[]>([]);

  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const animationRef = useRef<number | null>(null);
  const calibrationRef = useRef({ frame: 0, baselines: {} as any });
  
  // MediaPipe model references
  const faceMeshRef = useRef<FaceMesh | null>(null);
  const handsRef = useRef<Hands | null>(null);
  const poseRef = useRef<Pose | null>(null);
  const cameraRef = useRef<Camera | null>(null);

  const addLog = (message: string) => {
    const timestamp = new Date().toLocaleTimeString();
    setLogs(prev => [`${timestamp}: ${message}`, ...prev].slice(0, 10));
    console.log(`[Tracking] ${message}`);
  };

  const initializeMediaPipe = async () => {
    addLog('Initializing MediaPipe models...');
    
    try {
      // Initialize Face Mesh
      const faceMesh = new FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });
      
      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });
      
      faceMesh.onResults((results) => {
        if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
          processFaceResults(results);
        }
      });
      faceMeshRef.current = faceMesh;
      
      // Initialize Hands
      const hands = new Hands({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
      });
      
      hands.setOptions({
        maxNumHands: 2,
        modelComplexity: 1,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });
      
      hands.onResults((results) => {
        processHandResults(results);
      });
      handsRef.current = hands;
      
      // Initialize Pose
      const pose = new Pose({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
      });
      
      pose.setOptions({
        modelComplexity: 1,
        smoothLandmarks: true,
        enableSegmentation: false,
        smoothSegmentation: false,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });
      
      pose.onResults((results) => {
        processPoseResults(results);
      });
      poseRef.current = pose;
      
      addLog('MediaPipe models initialized');
      return true;
    } catch (error: any) {
      addLog(`MediaPipe initialization error: ${error.message}`);
      return false;
    }
  };

  const startCamera = async () => {
    try {
      addLog('Requesting camera access...');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user'
        }
      });
      
      addLog('Camera access granted');
      streamRef.current = stream;
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        await videoRef.current.play();
        addLog('Video playback started');
        
        // Initialize MediaPipe models
        const initialized = await initializeMediaPipe();
        if (!initialized) {
          addLog('Failed to initialize MediaPipe - falling back to basic tracking');
        }
        
        setCameraActive(true);
        setIsCalibrating(true);
        addLog('Starting real-time tracking...');
        startTracking();
      }
    } catch (err: any) {
      addLog(`Camera error: ${err.message}`);
      console.error('Camera error:', err.message);
    }
  };

  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
    }
    
    setCameraActive(false);
    setIsCalibrating(false);
    setFrameCount(0);
    calibrationRef.current = { frame: 0, baselines: {} };
  };

  const processFaceResults = (results: any) => {
    if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) return;
    
    const landmarks = results.multiFaceLandmarks[0];
    const expressions = calculateFacialExpressions(landmarks);
    const headRotation = calculateHeadRotation(landmarks);
    const eyeData = calculateEyeTracking(landmarks);
    const mouthData = calculateMouthMovement(landmarks);
    
    setTrackingData(prev => ({
      ...prev,
      face: {
        landmarks: landmarks.length,
        expressions,
        headRotation
      },
      eyes: eyeData,
      mouth: mouthData
    }));
    
    if (frameCount % 60 === 0) {
      addLog(`Face detected: ${landmarks.length} landmarks, expressions active`);
    }
  };

  const processHandResults = (results: any) => {
    const leftHand = results.multiHandLandmarks && results.multiHandedness ? 
      results.multiHandLandmarks.find((_: any, index: number) => 
        results.multiHandedness[index].label === 'Left') : null;
    const rightHand = results.multiHandLandmarks && results.multiHandedness ? 
      results.multiHandLandmarks.find((_: any, index: number) => 
        results.multiHandedness[index].label === 'Right') : null;
    
    setTrackingData(prev => ({
      ...prev,
      hands: {
        left: {
          detected: !!leftHand,
          landmarks: leftHand ? leftHand.length : 0,
          gesture: leftHand ? calculateHandGesture(leftHand) : 'none'
        },
        right: {
          detected: !!rightHand,
          landmarks: rightHand ? rightHand.length : 0,
          gesture: rightHand ? calculateHandGesture(rightHand) : 'none'
        }
      }
    }));
    
    if ((leftHand || rightHand) && frameCount % 30 === 0) {
      addLog(`Hands detected - Left: ${!!leftHand}, Right: ${!!rightHand}`);
    }
  };

  const processPoseResults = (results: any) => {
    if (!results.poseLandmarks) return;
    
    const landmarks = results.poseLandmarks;
    const confidence = calculatePoseConfidence(landmarks);
    
    setTrackingData(prev => ({
      ...prev,
      body: {
        pose: {
          detected: landmarks.length > 0,
          landmarks: landmarks.length,
          confidence
        },
        skeleton: {
          joints: 17, // Standard pose joint count
          tracking: confidence > 0.5
        }
      }
    }));
    
    if (landmarks.length > 0 && frameCount % 60 === 0) {
      addLog(`Body pose detected: ${landmarks.length} landmarks, confidence: ${(confidence * 100).toFixed(0)}%`);
    }
  };

  const analyzeFrame = async (video: HTMLVideoElement, canvas: HTMLCanvasElement) => {
    if (!video || video.videoWidth === 0) return;

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;
    
    ctx.drawImage(video, 0, 0);
    
    if (frameCount % 30 === 0) {
      addLog(`Processing frame ${frameCount} (${video.videoWidth}x${video.videoHeight})`);
    }

    // Send frame to MediaPipe models
    try {
      if (faceMeshRef.current) {
        await faceMeshRef.current.send({ image: video });
      }
      if (handsRef.current) {
        await handsRef.current.send({ image: video });
      }
      if (poseRef.current) {
        await poseRef.current.send({ image: video });
      }
    } catch (error: any) {
      if (frameCount % 120 === 0) { // Log errors every 4 seconds
        addLog(`MediaPipe processing error: ${error.message}`);
      }
    }
  };

  // Real MediaPipe data calculation functions
  const calculateFacialExpressions = (landmarks: any[]) => {
    // Real facial expression analysis using MediaPipe landmark positions
    // Mouth landmarks: 13, 14, 17, 18 for smile detection
    // Eye landmarks: 33, 7, 163, 144 for blink detection
    const mouth_left = landmarks[61];
    const mouth_right = landmarks[291];
    const mouth_top = landmarks[13];
    const mouth_bottom = landmarks[14];
    
    const eye_left_top = landmarks[159];
    const eye_left_bottom = landmarks[145];
    const eye_right_top = landmarks[386];
    const eye_right_bottom = landmarks[374];
    
    // Calculate mouth width vs height for smile detection
    const mouth_width = Math.abs(mouth_right.x - mouth_left.x);
    const mouth_height = Math.abs(mouth_bottom.y - mouth_top.y);
    const smile = Math.min(1, mouth_width / (mouth_height + 0.01) / 3);
    
    // Calculate eye openness for expressions
    const left_eye_height = Math.abs(eye_left_top.y - eye_left_bottom.y);
    const right_eye_height = Math.abs(eye_right_top.y - eye_right_bottom.y);
    const avg_eye_height = (left_eye_height + right_eye_height) / 2;
    
    return {
      smile: Math.max(0, Math.min(1, smile)),
      frown: Math.max(0, Math.min(1, 1 - smile)),
      eyebrowRaise: Math.max(0, Math.min(1, avg_eye_height * 15)),
      jawDrop: Math.max(0, Math.min(1, mouth_height * 10))
    };
  };

  const calculateHeadRotation = (landmarks: any[]) => {
    // Use nose tip, chin, and forehead points for rotation calculation
    const nose_tip = landmarks[1];
    const chin = landmarks[18];
    const forehead = landmarks[10];
    const left_face = landmarks[234];
    const right_face = landmarks[454];
    
    // Calculate yaw (left-right rotation)
    const face_width_left = Math.abs(nose_tip.x - left_face.x);
    const face_width_right = Math.abs(right_face.x - nose_tip.x);
    const yaw = (face_width_right - face_width_left) * 100;
    
    // Calculate pitch (up-down rotation)
    const face_height = Math.abs(forehead.y - chin.y);
    const nose_position = (nose_tip.y - forehead.y) / face_height;
    const pitch = (nose_position - 0.5) * 60;
    
    // Calculate roll using eye positions
    const left_eye = landmarks[33];
    const right_eye = landmarks[263];
    const eye_angle = Math.atan2(right_eye.y - left_eye.y, right_eye.x - left_eye.x);
    const roll = eye_angle * (180 / Math.PI);
    
    return { x: pitch, y: yaw, z: roll };
  };

  const calculateEyeTracking = (landmarks: any[]) => {
    // Left eye landmarks
    const left_eye_center = landmarks[468];
    const left_eye_left = landmarks[33];
    const left_eye_right = landmarks[133];
    const left_eye_top = landmarks[159];
    const left_eye_bottom = landmarks[145];
    
    // Right eye landmarks
    const right_eye_center = landmarks[473];
    const right_eye_left = landmarks[362];
    const right_eye_right = landmarks[263];
    const right_eye_top = landmarks[386];
    const right_eye_bottom = landmarks[374];
    
    // Calculate eye openness
    const left_openness = Math.abs(left_eye_top.y - left_eye_bottom.y) * 25;
    const right_openness = Math.abs(right_eye_top.y - right_eye_bottom.y) * 25;
    
    // Calculate gaze direction (simplified)
    const left_gaze_x = (left_eye_center ? left_eye_center.x : 0.5) - 0.5;
    const left_gaze_y = (left_eye_center ? left_eye_center.y : 0.5) - 0.5;
    const right_gaze_x = (right_eye_center ? right_eye_center.x : 0.5) - 0.5;
    const right_gaze_y = (right_eye_center ? right_eye_center.y : 0.5) - 0.5;
    
    // Detect blinking
    const blink_threshold = 0.02;
    const blinking = left_openness < blink_threshold && right_openness < blink_threshold;
    
    return {
      left: { openness: Math.min(1, left_openness), gaze: { x: left_gaze_x, y: left_gaze_y } },
      right: { openness: Math.min(1, right_openness), gaze: { x: right_gaze_x, y: right_gaze_y } },
      blinking
    };
  };

  const calculateMouthMovement = (landmarks: any[]) => {
    // Mouth landmarks for opening calculation
    const mouth_top = landmarks[13];
    const mouth_bottom = landmarks[14];
    const mouth_left = landmarks[61];
    const mouth_right = landmarks[291];
    
    // Calculate mouth opening
    const mouth_height = Math.abs(mouth_bottom.y - mouth_top.y);
    const mouth_width = Math.abs(mouth_right.x - mouth_left.x);
    const openness = Math.min(1, mouth_height * 15);
    
    // Determine mouth shape
    const aspect_ratio = mouth_width / (mouth_height + 0.001);
    let shape = 'closed';
    if (openness > 0.6) shape = 'open';
    else if (openness > 0.3) shape = 'partial';
    
    // Speaking detection based on mouth movement variation
    const speaking = openness > 0.2;
    const lipSync = speaking ? openness : 0;
    
    return { openness, shape, speaking, lipSync };
  };

  const calculateHandGesture = (handLandmarks: any[]) => {
    if (!handLandmarks || handLandmarks.length < 21) return 'none';
    
    // Analyze finger positions for gesture recognition
    const thumb_tip = handLandmarks[4];
    const index_tip = handLandmarks[8];
    const middle_tip = handLandmarks[12];
    const ring_tip = handLandmarks[16];
    const pinky_tip = handLandmarks[20];
    const wrist = handLandmarks[0];
    
    // Calculate distances from wrist to fingertips
    const thumb_dist = Math.sqrt(Math.pow(thumb_tip.x - wrist.x, 2) + Math.pow(thumb_tip.y - wrist.y, 2));
    const index_dist = Math.sqrt(Math.pow(index_tip.x - wrist.x, 2) + Math.pow(index_tip.y - wrist.y, 2));
    const middle_dist = Math.sqrt(Math.pow(middle_tip.x - wrist.x, 2) + Math.pow(middle_tip.y - wrist.y, 2));
    
    // Simple gesture classification
    if (index_dist > 0.15 && middle_dist < 0.12) return 'point';
    if (index_dist > 0.15 && middle_dist > 0.15) return 'wave';
    if (index_dist < 0.1 && middle_dist < 0.1) return 'fist';
    if (index_dist > 0.12 && middle_dist > 0.12 && thumb_dist > 0.12) return 'open';
    
    return 'none';
  };

  const calculatePoseConfidence = (poseLandmarks: any[]) => {
    if (!poseLandmarks || poseLandmarks.length === 0) return 0;
    
    // Calculate average visibility/confidence from pose landmarks
    let totalConfidence = 0;
    let validPoints = 0;
    
    poseLandmarks.forEach((landmark: any) => {
      if (landmark.visibility !== undefined && landmark.visibility > 0) {
        totalConfidence += landmark.visibility;
        validPoints++;
      }
    });
    
    return validPoints > 0 ? totalConfidence / validPoints : 0;
  };

  const analyzeFaceFeatures = (canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D) => {
    // Simulate 468-point face landmark detection (MediaPipe style)
    const centerX = canvas.width / 2;
    const centerY = canvas.height / 2;
    
    // Analyze face region for expressions
    const faceRegion = ctx.getImageData(centerX - 100, centerY - 80, 200, 160);
    const brightness = calculateAverageBrightness(faceRegion.data);
    
    // Generate more dynamic expressions based on brightness and time
    const time = Date.now() / 1000;
    const brightness_normalized = Math.max(0, Math.min(1, brightness / 255));
    
    const expressions = {
      smile: Math.max(0, Math.min(1, brightness_normalized * 0.7 + Math.sin(time * 0.3) * 0.3)),
      frown: Math.max(0, Math.min(1, (1 - brightness_normalized) * 0.5 + Math.cos(time * 0.4) * 0.2)),
      eyebrowRaise: Math.max(0, Math.min(1, Math.sin(time * 0.2) * 0.4 + 0.3)),
      jawDrop: Math.max(0, Math.min(1, brightness_normalized * 0.6 + Math.sin(time * 0.5) * 0.2))
    };

    // Simulate head rotation based on face asymmetry and movement
    const leftSide = ctx.getImageData(centerX - 100, centerY - 60, 50, 120);
    const rightSide = ctx.getImageData(centerX + 50, centerY - 60, 50, 120);
    const asymmetry = calculateAverageBrightness(leftSide.data) - calculateAverageBrightness(rightSide.data);
    
    return {
      landmarks: 468,
      expressions,
      headRotation: {
        x: Math.sin(time / 2) * 20 + (asymmetry * 0.1), // Pitch
        y: asymmetry * 0.3 + Math.cos(time / 3) * 15, // Yaw
        z: Math.cos(time / 2.5) * 12 // Roll
      }
    };
  };

  const analyzeHandGestures = (canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D) => {
    // Analyze left and right hand regions
    const leftHandRegion = ctx.getImageData(canvas.width * 0.2, canvas.height * 0.6, 100, 120);
    const rightHandRegion = ctx.getImageData(canvas.width * 0.7, canvas.height * 0.6, 100, 120);
    
    const leftMotion = calculateMotionIntensity(leftHandRegion.data);
    const rightMotion = calculateMotionIntensity(rightHandRegion.data);
    
    // Add time-based variation for more realistic detection
    const time = Date.now() / 1000;
    const leftActivity = Math.max(0.2, leftMotion + Math.sin(time * 0.8) * 0.3);
    const rightActivity = Math.max(0.2, rightMotion + Math.cos(time * 0.6) * 0.3);
    
    const gestures = ['none', 'point', 'wave', 'fist', 'open'];
    
    return {
      left: {
        detected: leftActivity > 0.4,
        landmarks: leftActivity > 0.4 ? 21 : 0,
        gesture: leftActivity > 0.7 ? 'wave' : leftActivity > 0.5 ? 'point' : 'none'
      },
      right: {
        detected: rightActivity > 0.4,
        landmarks: rightActivity > 0.4 ? 21 : 0,
        gesture: rightActivity > 0.7 ? 'wave' : rightActivity > 0.5 ? 'point' : 'none'
      }
    };
  };

  const analyzeBodyPose = (canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D) => {
    // Analyze full body region for pose detection
    const bodyRegion = ctx.getImageData(canvas.width * 0.25, canvas.height * 0.3, canvas.width * 0.5, canvas.height * 0.6);
    const poseIntensity = calculateMotionIntensity(bodyRegion.data);
    
    return {
      pose: {
        detected: poseIntensity > 0.2,
        landmarks: poseIntensity > 0.2 ? 33 : 0,
        confidence: Math.min(1, poseIntensity * 2)
      },
      skeleton: {
        joints: poseIntensity > 0.2 ? 17 : 0,
        tracking: poseIntensity > 0.4
      }
    };
  };

  const analyzeEyeMovement = (canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D) => {
    const centerX = canvas.width / 2;
    const centerY = canvas.height / 2;
    
    // Analyze eye regions
    const leftEyeRegion = ctx.getImageData(centerX - 60, centerY - 30, 30, 20);
    const rightEyeRegion = ctx.getImageData(centerX + 30, centerY - 30, 30, 20);
    
    const leftBrightness = calculateAverageBrightness(leftEyeRegion.data);
    const rightBrightness = calculateAverageBrightness(rightEyeRegion.data);
    
    // Simulate blinking detection
    const blinking = leftBrightness < 80 && rightBrightness < 80;
    
    return {
      left: {
        openness: Math.max(0.1, Math.min(1, leftBrightness / 120)),
        gaze: { x: Math.sin(Date.now() / 5000) * 0.3, y: Math.cos(Date.now() / 7000) * 0.2 }
      },
      right: {
        openness: Math.max(0.1, Math.min(1, rightBrightness / 120)),
        gaze: { x: Math.sin(Date.now() / 5000) * 0.3, y: Math.cos(Date.now() / 7000) * 0.2 }
      },
      blinking
    };
  };

  const analyzeMouthMovement = (canvas: HTMLCanvasElement, ctx: CanvasRenderingContext2D) => {
    const centerX = canvas.width / 2;
    const centerY = canvas.height * 0.75;
    
    // Analyze mouth region
    const mouthRegion = ctx.getImageData(centerX - 40, centerY - 20, 80, 40);
    const mouthBrightness = calculateAverageBrightness(mouthRegion.data);
    
    // Detect lip color pixels for more accurate mouth tracking
    let lipPixels = 0;
    const data = mouthRegion.data;
    for (let i = 0; i < data.length; i += 4) {
      const r = data[i], g = data[i + 1], b = data[i + 2];
      if (r > g + 10 && r > b + 5 && r > 100) lipPixels++;
    }
    
    // Generate more dynamic mouth movement
    const time = Date.now() / 1000;
    const brightness_normalized = mouthBrightness / 255;
    const openness = Math.max(0, Math.min(1, brightness_normalized * 0.8 + Math.sin(time * 2) * 0.3));
    const speaking = openness > 0.4 || Math.sin(time * 3) > 0.6;
    
    return {
      openness,
      shape: openness > 0.6 ? 'open' : openness > 0.3 ? 'partial' : 'closed',
      speaking,
      lipSync: speaking ? Math.abs(Math.sin(time * 4)) : 0
    };
  };

  const calculateAverageBrightness = (data: Uint8ClampedArray): number => {
    let total = 0;
    for (let i = 0; i < data.length; i += 4) {
      total += (data[i] + data[i + 1] + data[i + 2]) / 3;
    }
    return total / (data.length / 4);
  };

  const calculateMotionIntensity = (data: Uint8ClampedArray): number => {
    let edgeIntensity = 0;
    const width = Math.sqrt(data.length / 4);
    
    for (let i = 0; i < data.length - 16; i += 4) {
      const current = (data[i] + data[i + 1] + data[i + 2]) / 3;
      const next = (data[i + 4] + data[i + 5] + data[i + 6]) / 3;
      edgeIntensity += Math.abs(current - next);
    }
    
    return Math.min(1, edgeIntensity / (data.length / 4) / 50);
  };

  const startTracking = () => {
    const trackingLoop = () => {
      if (!cameraActive) return;
      
      const video = videoRef.current;
      const canvas = canvasRef.current;
      
      if (video && canvas && video.readyState >= 2) {
        analyzeFrame(video, canvas);
        
        // Update frame count and calibration
        const currentFrame = frameCount + 1;
        setFrameCount(currentFrame);
        
        if (currentFrame <= 120) { // 4 seconds calibration
          calibrationRef.current.frame = currentFrame;
          if (currentFrame === 120) {
            setIsCalibrating(false);
            addLog('Calibration complete - real tracking active');
          }
        }
      }
      
      animationRef.current = requestAnimationFrame(trackingLoop);
    };
    
    trackingLoop();
  };

  useEffect(() => {
    return () => stopCamera();
  }, []);

  const getStatusColor = (value: number) => {
    if (value > 0.7) return 'bg-green-500';
    if (value > 0.3) return 'bg-yellow-500';
    return 'bg-red-500';
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-slate-900 to-slate-800 p-4">
      <div className="max-w-7xl mx-auto space-y-6">
        <Card className="border-slate-600 bg-slate-800">
          <CardHeader>
            <CardTitle className="text-white flex items-center justify-between">
              Comprehensive Avatar Tracking System
              <Badge variant={cameraActive ? "default" : "secondary"} className="ml-2">
                {cameraActive ? "Active" : "Inactive"}
              </Badge>
            </CardTitle>
          </CardHeader>
          <CardContent className="space-y-4">
            <div className="flex gap-4">
              <Button 
                onClick={cameraActive ? stopCamera : startCamera}
                variant={cameraActive ? "destructive" : "default"}
              >
                {cameraActive ? "Stop Tracking" : "Start Tracking"}
              </Button>
              
              {isCalibrating && (
                <div className="flex items-center gap-2">
                  <span className="text-slate-300 text-sm">Calibrating...</span>
                  <Progress value={(frameCount / 120) * 100} className="w-32" />
                </div>
              )}
            </div>
            
            <div className="grid grid-cols-1 lg:grid-cols-2 gap-4">
              <div className="space-y-4">
                <video
                  ref={videoRef}
                  className="w-full rounded-lg border border-slate-600"
                  playsInline
                  muted
                />
                <canvas ref={canvasRef} className="hidden" />
              </div>
              
              <div className="space-y-4">
                <div className="text-slate-300 text-sm">
                  Frame: {frameCount} | Status: {isCalibrating ? 'Calibrating' : 'Tracking'}
                </div>
                
                {/* Real-time Log Panel */}
                <Card className="border-slate-600 bg-slate-700 max-h-64 overflow-hidden">
                  <CardHeader className="pb-2">
                    <CardTitle className="text-white text-sm">System Log</CardTitle>
                  </CardHeader>
                  <CardContent className="pt-0">
                    <div className="text-xs space-y-1 max-h-48 overflow-y-auto">
                      {logs.length === 0 ? (
                        <div className="text-slate-400">No logs yet...</div>
                      ) : (
                        logs.map((log, index) => (
                          <div key={index} className="text-slate-200 font-mono">
                            {log}
                          </div>
                        ))
                      )}
                    </div>
                  </CardContent>
                </Card>
              </div>
            </div>
          </CardContent>
        </Card>

        {/* Face Tracking Card */}
        <Card className="border-slate-600 bg-slate-800">
          <CardHeader>
            <CardTitle className="text-white flex items-center text-lg">
              <div className={`w-4 h-4 rounded-full mr-3 ${getStatusColor(trackingData.face.landmarks / 468)}`}></div>
              Face Tracking
              <Badge className="ml-2 bg-blue-600">{trackingData.face.landmarks} landmarks</Badge>
            </CardTitle>
          </CardHeader>
          <CardContent>
            <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
              <div className="space-y-3">
                <div className="text-slate-400 font-medium">Expressions</div>
                {Object.entries(trackingData.face.expressions).map(([expr, value]) => (
                  <div key={expr} className="space-y-1">
                    <div className="flex justify-between text-sm">
                      <span className="text-slate-300 capitalize">{expr}</span>
                      <span className="text-white font-mono">{(value * 100).toFixed(0)}%</span>
                    </div>
                    <Progress value={value * 100} className="h-2" />
                  </div>
                ))}
              </div>
              
              <div className="space-y-3">
                <div className="text-slate-400 font-medium">Head Rotation</div>
                <div className="space-y-2">
                  {[
                    { label: 'X (Pitch)', value: trackingData.face.headRotation.x },
                    { label: 'Y (Yaw)', value: trackingData.face.headRotation.y },
                    { label: 'Z (Roll)', value: trackingData.face.headRotation.z }
                  ].map(({ label, value }) => (
                    <div key={label} className="flex justify-between items-center">
                      <span className="text-slate-300 text-sm">{label}:</span>
                      <Badge variant="outline" className="text-white border-slate-500 font-mono">
                        {value.toFixed(1)}Â°
                      </Badge>
                    </div>
                  ))}
                </div>
              </div>
            </div>
          </CardContent>
        </Card>

        {/* Hand Tracking Card */}
        <Card className="border-slate-600 bg-slate-800">
          <CardHeader>
            <CardTitle className="text-white flex items-center">
              <div className={`w-3 h-3 rounded-full mr-2 ${getStatusColor(trackingData.hands.left.detected && trackingData.hands.right.detected ? 1 : 0.5)}`}></div>
              Hand Tracking (21 Points Each)
            </CardTitle>
          </CardHeader>
          <CardContent>
            <div className="grid grid-cols-2 gap-4">
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Left Hand</div>
                <Badge variant={trackingData.hands.left.detected ? "default" : "secondary"}>
                  {trackingData.hands.left.detected ? "Detected" : "Not Detected"}
                </Badge>
                <div className="flex justify-between">
                  <span className="text-slate-300">Landmarks:</span>
                  <span className="text-white">{trackingData.hands.left.landmarks}</span>
                </div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Gesture:</span>
                  <span className="text-white capitalize">{trackingData.hands.left.gesture}</span>
                </div>
              </div>
              
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Right Hand</div>
                <Badge variant={trackingData.hands.right.detected ? "default" : "secondary"}>
                  {trackingData.hands.right.detected ? "Detected" : "Not Detected"}
                </Badge>
                <div className="flex justify-between">
                  <span className="text-slate-300">Landmarks:</span>
                  <span className="text-white">{trackingData.hands.right.landmarks}</span>
                </div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Gesture:</span>
                  <span className="text-white capitalize">{trackingData.hands.right.gesture}</span>
                </div>
              </div>
            </div>
          </CardContent>
        </Card>

        {/* Body Pose Card */}
        <Card className="border-slate-600 bg-slate-800">
          <CardHeader>
            <CardTitle className="text-white flex items-center">
              <div className={`w-3 h-3 rounded-full mr-2 ${getStatusColor(trackingData.body.pose.confidence)}`}></div>
              Body Pose Tracking (33 Landmarks)
            </CardTitle>
          </CardHeader>
          <CardContent>
            <div className="grid grid-cols-2 gap-4">
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Pose Detection</div>
                <Badge variant={trackingData.body.pose.detected ? "default" : "secondary"}>
                  {trackingData.body.pose.detected ? "Detected" : "Not Detected"}
                </Badge>
                <div className="flex justify-between">
                  <span className="text-slate-300">Landmarks:</span>
                  <span className="text-white">{trackingData.body.pose.landmarks}</span>
                </div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Confidence:</span>
                  <span className="text-white">{(trackingData.body.pose.confidence * 100).toFixed(0)}%</span>
                </div>
              </div>
              
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Skeleton</div>
                <Badge variant={trackingData.body.skeleton.tracking ? "default" : "secondary"}>
                  {trackingData.body.skeleton.tracking ? "Tracking" : "Not Tracking"}
                </Badge>
                <div className="flex justify-between">
                  <span className="text-slate-300">Joints:</span>
                  <span className="text-white">{trackingData.body.skeleton.joints}</span>
                </div>
              </div>
            </div>
          </CardContent>
        </Card>

        {/* Eye Tracking Card */}
        <Card className="border-slate-600 bg-slate-800">
          <CardHeader>
            <CardTitle className="text-white flex items-center">
              <div className={`w-3 h-3 rounded-full mr-2 ${getStatusColor((trackingData.eyes.left.openness + trackingData.eyes.right.openness) / 2)}`}></div>
              Eye Tracking & Gaze Detection
            </CardTitle>
          </CardHeader>
          <CardContent>
            <div className="grid grid-cols-3 gap-4">
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Left Eye</div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Openness:</span>
                  <span className="text-white">{(trackingData.eyes.left.openness * 100).toFixed(0)}%</span>
                </div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Gaze X:</span>
                  <span className="text-white">{trackingData.eyes.left.gaze.x.toFixed(2)}</span>
                </div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Gaze Y:</span>
                  <span className="text-white">{trackingData.eyes.left.gaze.y.toFixed(2)}</span>
                </div>
              </div>
              
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Right Eye</div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Openness:</span>
                  <span className="text-white">{(trackingData.eyes.right.openness * 100).toFixed(0)}%</span>
                </div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Gaze X:</span>
                  <span className="text-white">{trackingData.eyes.right.gaze.x.toFixed(2)}</span>
                </div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Gaze Y:</span>
                  <span className="text-white">{trackingData.eyes.right.gaze.y.toFixed(2)}</span>
                </div>
              </div>
              
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Status</div>
                <Badge variant={trackingData.eyes.blinking ? "destructive" : "default"}>
                  {trackingData.eyes.blinking ? "Blinking" : "Open"}
                </Badge>
              </div>
            </div>
          </CardContent>
        </Card>

        {/* Mouth Tracking Card */}
        <Card className="border-slate-600 bg-slate-800">
          <CardHeader>
            <CardTitle className="text-white flex items-center">
              <div className={`w-3 h-3 rounded-full mr-2 ${getStatusColor(trackingData.mouth.openness)}`}></div>
              Mouth & Speech Tracking
            </CardTitle>
          </CardHeader>
          <CardContent>
            <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Opening</div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Amount:</span>
                  <span className="text-white">{(trackingData.mouth.openness * 100).toFixed(0)}%</span>
                </div>
                <Progress value={trackingData.mouth.openness * 100} className="w-full" />
              </div>
              
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Shape</div>
                <Badge variant="outline" className="text-white border-slate-500">
                  {trackingData.mouth.shape}
                </Badge>
              </div>
              
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Speech</div>
                <Badge variant={trackingData.mouth.speaking ? "default" : "secondary"}>
                  {trackingData.mouth.speaking ? "Speaking" : "Silent"}
                </Badge>
              </div>
              
              <div className="space-y-2">
                <div className="text-slate-400 text-sm">Lip Sync</div>
                <div className="flex justify-between">
                  <span className="text-slate-300">Intensity:</span>
                  <span className="text-white">{(trackingData.mouth.lipSync * 100).toFixed(0)}%</span>
                </div>
              </div>
            </div>
          </CardContent>
        </Card>
      </div>
    </div>
  );
}