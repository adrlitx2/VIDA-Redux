import OpenAI from 'openai';
import sharp from 'sharp';

/**
 * Test Avatar Completion Service
 * Uses DALL-E 3 to generate complete full-body characters from partial character images
 * This is a standalone test service for avatar completion functionality
 */
export class CharacterCompletionTest {
  private openai: OpenAI;

  constructor() {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OPENAI_API_KEY is required for character completion');
    }
    
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }

  /**
   * Complete a partial character into a full-body character
   */
  async completeCharacter(
    imageBuffer: Buffer,
    userPlan: string = 'free',
    options: {
      style?: 'realistic' | 'cartoon' | 'anime' | 'fantasy';
      quality?: 'standard' | 'hd';
      size?: '1024x1024' | '1792x1024' | '1024x1792';
      customPrompt?: string;
    } = {}
  ): Promise<{
    completedImageUrl: string;
    completedImageBuffer: Buffer;
    originalAnalysis: any;
    completionPrompt: string;
    processingTime: number;
  }> {
    const startTime = Date.now();
    console.log('üé® Starting avatar completion test...');

    try {
      // Analyze the original partial character
      const originalAnalysis = await this.analyzePartialCharacter(imageBuffer);
      console.log('üìä Character analysis:', originalAnalysis);

      // Generate completion prompt based on analysis
      const completionPrompt = options.customPrompt || 
        this.generateCompletionPrompt(originalAnalysis, options.style);
      console.log('‚úçÔ∏è Generated prompt:', completionPrompt);

      // Configure quality based on subscription plan and options
      const imageConfig = this.getImageConfigForPlan(userPlan, options);

      // Generate completed character using DALL-E 3
      console.log('üé® Generating complete character with DALL-E 3...');
      console.log('üé® Using prompt:', completionPrompt);
      console.log('üé® Image config:', imageConfig);
      
      let completedImageUrl: string;
      let completedImageBuffer: Buffer;

      try {
        const response = await this.openai.images.generate({
          model: "dall-e-3",
          prompt: completionPrompt,
          size: imageConfig.size,
          quality: imageConfig.quality,
          style: imageConfig.style,
          n: 1,
        });

        if (!response.data[0]?.url) {
          throw new Error('No image generated by DALL-E 3');
        }

        completedImageUrl = response.data[0].url;
        console.log('‚úÖ Character completion successful:', completedImageUrl);

        // Download the generated image
        const imageResponse = await fetch(completedImageUrl);
        if (!imageResponse.ok) {
          throw new Error('Failed to download generated image');
        }

        completedImageBuffer = Buffer.from(await imageResponse.arrayBuffer());

      } catch (dalleError: any) {
        console.warn('‚ö†Ô∏è DALL-E 3 generation failed, creating demonstration completion:', dalleError.message);
        
        // Create a demonstration completion by enhancing the original image
        completedImageBuffer = await this.createDemoCompletion(imageBuffer, originalAnalysis);
        completedImageUrl = 'demo_completion'; // Will be served locally
      }
      const processingTime = Date.now() - startTime;

      console.log(`üéâ Character completion complete in ${processingTime}ms`);

      return {
        completedImageUrl,
        completedImageBuffer,
        originalAnalysis,
        completionPrompt,
        processingTime
      };

    } catch (error) {
      console.error('‚ùå Character completion failed:', error);
      throw new Error(`Character completion failed: ${error.message}`);
    }
  }

  /**
   * Analyze partial character to understand what needs completion
   * Uses basic image analysis when OpenAI API is unavailable
   */
  private async analyzePartialCharacter(imageBuffer: Buffer): Promise<{
    characterType: string;
    visibleParts: string[];
    missingParts: string[];
    style: string;
    colors: string[];
    traits: string[];
    pose: string;
  }> {
    try {
      // Get image metadata for basic analysis
      const metadata = await sharp(imageBuffer).metadata();
      console.log('üìä Image metadata:', { width: metadata.width, height: metadata.height, format: metadata.format });

      // Try OpenAI Vision analysis first
      const base64Image = imageBuffer.toString('base64');

      const analysisResponse = await this.openai.chat.completions.create({
        model: "gpt-4o", // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
        messages: [
          {
            role: "user",
            content: [
              {
                type: "text",
                text: `Analyze this partial character image and identify:
1. Character type (human, animal, cartoon, fantasy, robot, etc.)
2. Visible body parts (head, torso, arms, legs, etc.)
3. Missing body parts that need completion
4. Art style (realistic, cartoon, anime, pixel art, etc.)
5. Dominant colors
6. Character traits (clothing, accessories, facial features)
7. Current pose or position

Respond in JSON format with the fields: characterType, visibleParts, missingParts, style, colors, traits, pose`
              },
              {
                type: "image_url",
                image_url: {
                  url: `data:image/jpeg;base64,${base64Image}`
                }
              }
            ]
          }
        ],
        response_format: { type: "json_object" },
        max_tokens: 500
      });

      const analysisText = analysisResponse.choices[0].message.content;
      const analysis = JSON.parse(analysisText);

      return {
        characterType: analysis.characterType || 'character',
        visibleParts: analysis.visibleParts || ['head'],
        missingParts: analysis.missingParts || ['torso', 'arms', 'legs'],
        style: analysis.style || 'cartoon',
        colors: analysis.colors || ['various'],
        traits: analysis.traits || [],
        pose: analysis.pose || 'standing'
      };

    } catch (error) {
      console.warn('‚ö†Ô∏è OpenAI Vision analysis failed, using enhanced fallback analysis:', error.message);
      
      // Enhanced fallback analysis using image processing
      return await this.fallbackImageAnalysis(imageBuffer);
    }
  }

  /**
   * Enhanced fallback analysis when OpenAI Vision is unavailable
   */
  private async fallbackImageAnalysis(imageBuffer: Buffer): Promise<{
    characterType: string;
    visibleParts: string[];
    missingParts: string[];
    style: string;
    colors: string[];
    traits: string[];
    pose: string;
  }> {
    try {
      const metadata = await sharp(imageBuffer).metadata();
      
      // Basic image analysis
      const { dominant } = await sharp(imageBuffer)
        .resize(100, 100)
        .raw()
        .toBuffer({ resolveWithObject: true });

      // Estimate image characteristics based on metadata and basic analysis
      const isWide = (metadata.width || 0) > (metadata.height || 0);
      const aspectRatio = (metadata.width || 1) / (metadata.height || 1);
      
      // Determine likely character type based on aspect ratio and size
      let characterType = 'character';
      let style = 'cartoon';
      let visibleParts = ['head'];
      let missingParts = ['torso', 'arms', 'legs'];
      
      if (aspectRatio > 1.5) {
        // Wide image - likely full body or landscape
        visibleParts = ['head', 'torso', 'arms'];
        missingParts = ['legs', 'feet'];
        characterType = 'full_character';
      } else if (aspectRatio < 0.7) {
        // Tall image - likely portrait or upper body
        visibleParts = ['head', 'shoulders'];
        missingParts = ['torso', 'arms', 'legs'];
        characterType = 'portrait';
      }

      // Analyze basic color information
      const colors = ['mixed_colors']; // Basic fallback
      
      return {
        characterType,
        visibleParts,
        missingParts,
        style,
        colors,
        traits: ['partial_character'],
        pose: 'standing'
      };

    } catch (error) {
      console.warn('‚ö†Ô∏è Fallback analysis also failed, using minimal defaults:', error);
      
      // Ultimate fallback with minimal analysis
      return {
        characterType: 'character',
        visibleParts: ['head'],
        missingParts: ['torso', 'arms', 'legs'],
        style: 'cartoon',
        colors: ['various'],
        traits: ['needs_completion'],
        pose: 'standing'
      };
    }
  }

  /**
   * Generate DALL-E 3 prompt for character completion
   */
  private generateCompletionPrompt(analysis: any, requestedStyle?: string): string {
    // Always use the original detected style to maintain authenticity
    const originalStyle = analysis.style || 'cartoon';
    const characterType = analysis.characterType || 'character';
    const colors = analysis.colors?.join(', ') || 'existing colors';
    const traits = analysis.traits?.length > 0 ? analysis.traits.join(', ') : 'existing traits';
    const visibleParts = analysis.visibleParts || ['head'];
    const missingParts = analysis.missingParts || ['torso', 'arms', 'legs'];
    
    // Build faithful completion prompt
    let prompt = `Complete this EXACT ${characterType} character by seamlessly extending the missing body parts while preserving EVERY detail of the existing character. `;
    
    // Emphasize preservation of existing elements
    prompt += `The visible parts (${visibleParts.join(', ')}) must remain completely unchanged - same colors, same style, same proportions, same details. `;
    
    // Specify natural extension of missing parts
    prompt += `Naturally extend and complete these missing parts: ${missingParts.join(', ')} as if they were always part of this exact character. `;
    
    // Absolute style consistency
    prompt += `Maintain the EXACT ${originalStyle} art style, line quality, shading, and rendering technique. `;
    
    // Color and trait preservation
    prompt += `Use the exact same color palette (${colors}) and preserve all character traits (${traits}). `;
    
    // Completion guidelines
    prompt += `The completed character should show a full body in a natural ${analysis.pose || 'standing'} pose. `;
    prompt += `No artistic interpretation - only faithful completion of the existing character design. `;
    prompt += `High quality, detailed, professional ${originalStyle} artwork.`;

    return prompt;
  }

  /**
   * Get image configuration based on user plan and options
   */
  private getImageConfigForPlan(userPlan: string, options: any) {
    const baseConfig = {
      size: options.size || '1024x1024',
      quality: options.quality || 'standard',
      style: 'natural' as const
    };

    switch (userPlan.toLowerCase()) {
      case 'goat':
      case 'zeus':
        return {
          ...baseConfig,
          quality: 'hd' as const,
          style: 'vivid' as const
        };
      case 'spartan':
        return {
          ...baseConfig,
          quality: 'hd' as const
        };
      default:
        return baseConfig;
    }
  }

  /**
   * Enhance the completed character with post-processing
   */
  async enhanceCompletedCharacter(
    imageBuffer: Buffer,
    userPlan: string
  ): Promise<Buffer> {
    try {
      let sharpInstance = sharp(imageBuffer);

      // Apply plan-specific enhancements
      switch (userPlan.toLowerCase()) {
        case 'goat':
          // Premium enhancement for Goat plan
          sharpInstance = sharpInstance
            .sharpen(1.2)
            .modulate({ brightness: 1.05, saturation: 1.1 });
          break;
        case 'zeus':
          // High-quality enhancement for Zeus plan
          sharpInstance = sharpInstance
            .sharpen(1.1)
            .modulate({ brightness: 1.03, saturation: 1.05 });
          break;
        case 'spartan':
          // Standard enhancement for Spartan plan
          sharpInstance = sharpInstance
            .sharpen(1.05);
          break;
        default:
          // Minimal enhancement for free plan
          break;
      }

      return await sharpInstance
        .jpeg({ quality: 95, progressive: true })
        .toBuffer();

    } catch (error) {
      console.warn('Enhancement failed, returning original:', error);
      return imageBuffer;
    }
  }

  /**
   * Create a demo completion when DALL-E 3 is unavailable
   * This enhances the original image to demonstrate the completion concept
   */
  private async createDemoCompletion(
    originalImageBuffer: Buffer,
    analysis: any
  ): Promise<Buffer> {
    try {
      console.log('üé® Creating demo completion for testing...');
      
      const metadata = await sharp(originalImageBuffer).metadata();
      const width = metadata.width || 512;
      const height = metadata.height || 512;
      
      // Create a larger canvas for the completed character
      const canvasWidth = Math.max(width, 512);
      const canvasHeight = Math.max(height * 1.5, 768); // Make taller to show completion
      
      // Create a background
      const background = await sharp({
        create: {
          width: canvasWidth,
          height: canvasHeight,
          channels: 3,
          background: { r: 240, g: 248, b: 255 } // Light blue background
        }
      }).jpeg().toBuffer();

      // Resize and position the original image in the upper part
      const resizedOriginal = await sharp(originalImageBuffer)
        .resize(canvasWidth * 0.8, null, { 
          fit: 'inside',
          withoutEnlargement: false 
        })
        .toBuffer();

      // Create text overlay for demo
      const textOverlay = `
<svg width="${canvasWidth}" height="${canvasHeight}">
  <rect width="100%" height="100%" fill="rgba(255,255,255,0.1)"/>
  <text x="${canvasWidth/2}" y="${canvasHeight * 0.75}" 
        text-anchor="middle" 
        font-family="Arial, sans-serif" 
        font-size="24" 
        fill="#333"
        font-weight="bold">
    CHARACTER COMPLETION DEMO
  </text>
  <text x="${canvasWidth/2}" y="${canvasHeight * 0.82}" 
        text-anchor="middle" 
        font-family="Arial, sans-serif" 
        font-size="16" 
        fill="#666">
    Original: ${analysis.characterType || 'Character'}
  </text>
  <text x="${canvasWidth/2}" y="${canvasHeight * 0.87}" 
        text-anchor="middle" 
        font-family="Arial, sans-serif" 
        font-size="16" 
        fill="#666">
    Style: ${analysis.style || 'Cartoon'}
  </text>
  <text x="${canvasWidth/2}" y="${canvasHeight * 0.92}" 
        text-anchor="middle" 
        font-family="Arial, sans-serif" 
        font-size="14" 
        fill="#999">
    Demo mode - OpenAI API unavailable
  </text>
</svg>`;

      // Composite the demo completion
      const demoCompletion = await sharp(background)
        .composite([
          {
            input: resizedOriginal,
            top: Math.round(canvasHeight * 0.1),
            left: Math.round((canvasWidth - (canvasWidth * 0.8)) / 2)
          },
          {
            input: Buffer.from(textOverlay),
            top: 0,
            left: 0
          }
        ])
        .jpeg({ quality: 90 })
        .toBuffer();

      console.log('‚úÖ Demo completion created successfully');
      return demoCompletion;

    } catch (error) {
      console.warn('‚ö†Ô∏è Demo completion creation failed, using original image:', error);
      
      // If demo creation fails, just enhance the original slightly
      return await sharp(originalImageBuffer)
        .resize(512, 768, { fit: 'inside', background: { r: 240, g: 248, b: 255 } })
        .jpeg({ quality: 90 })
        .toBuffer();
    }
  }
}